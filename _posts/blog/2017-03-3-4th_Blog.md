---
layout: single
title: Practical Guide of RNN in Tensorflow and Keras
modified:
categories: blog
excerpt: This is a practical guide of the implementation of RNN, especially the Sequence to Sequence model in Tensorflow and Keras.
tags: [Tensorflow, Keras, RNN]
date: 2017-04-3T17:35:45-00:00
--- 

# Introduction

In last three weeks, I tried to build a toy chatbot in both Keras(using TF as backend) and directly in TF. These two models work similar in their achitecture but they gave very different results and they are still very far away from actually being useful in any real world cases.  

When I was researching for any working examples, I felt frustrated as there isn't any practical guide on how Keras and Tensorflow works in a typical RNN model. I tried a lot of different examples but they are just pain in the ass. 

After seeing some results of my model, I felt I am able to help others in the understanding of practical RNN. That's what motivates me to write down this practical guide of RNN.  

Before we start, here is a screenshot of my chatbot results. I asked some aggressive questions to the bot because the bot is trained on Reddit and I suppose it to respond better to those conversations rather than the rest.

![conversationlog](/assets/images/conversation.png)

# 1. Preparation

## 1.1 Raw Data

I took a month of Reddit data and it is already **35G** decompressed. What I did originally is to split the dataset into few seperate CSV file, find the question and answer pair with a filter of max length 20 and min length 3. 

I wanted a smaller dataset to quickly come up with some good results but if I had more time I would try the model on the complete dataset. However, long sentences are always issues for training in terms of training time and complexity.   

## 1.2 Using Keras and Tensorflow

Personally I think using Keras is productive but TensorFlow is better if you are constantly looking for advanced new models.  Keras is a very new library so you probably will not see a lot of new theories implemented in Keras. However, most scholars today use TensorFlow for their papers. For example, I had a very bad experience building myself a Sequence with Attention model in Keras (which is not available in Keras yet) but it has been around in Tensorflow for a while already.  
  
  >There does exist a package called [Seq2seq](https://github.com/farizrahman4u/seq2seq) written by Fariz Rahman trying to implement the Attention Model for Keras. However, it has a lot of bugs and has been out of maintainence for a while. Plus, it only supports Theano as backend as far as my personal experience.     
   
[Tensorflow Example Library](https://github.com/tensorflow/models) is a very active and complete resource for most advanced models in the industry(from papers published in last year or even this year). **Plus, Neural Networks take long time to train, sometimes up to months. It makes you feel much saver to work with some models that you are certain will work (All TF model examples have approved working model weights and published papers)!**
  
*To conclude, I would suggest a beginner to learn the fundamentals, building RNN examples in Tensorflow and then play with Keras later. If you are dealing with images, Keras is powerful and is easy to use*. 

# 2. Data preparation

The first step is to prepare the dataset as much as I can so the training process becomes easier later. There are four things I am able to prepare in advance:
1. Index to words. This is a python list of the vocabulary.
2. Word to index. This is a python dict of word:index. 
3. Questions can be stored as list of lists of word index (even though it will transformed back into one-hot encoder matrix later in Keras). 
4. Output, in this case being the answers, is supposed to be one-hot encoded 

## 2.1 Buidling the dictionary

### 2.1.1 Limiting Dictionary size

To simplify the process, I removed the punctuations and lower all the characters in the dataset.  Still, there are over 200,000 unique words in the dataset.  
  
There are two reasons why we need to lower our dictionary size:  
  
  1. For most text understanding tasks, it is almost default that we use a embedding layer as the first layer. Even if we use Glove pretrained model, it will be a matrix of 2 x 10\*\*5 x 300 x batch-size, a matrix around 1GB if you put that in memory. Plus, the output is going to be one-hot encoded. The matrix is going be batch-size X sequence_length X vocab_size, which consumes another gigabyte of memory. **It is a good habit to mind check the memory size** because it just happens so often.

  2. There are so many words that are useless in terms of our conversational agent task. It creates a lot of noise and makes our model much harder to converge. In addition, remember the output of the model is going to be probabilities of each word. Having a huge dict is going to slow activation calcultion significantly.

### 2.1.2 Zipf's Law

Luckily, the existence of Zipf's law helped us to filter most of the useless words. Basically the law says the 2nd most frequent words appears about half of the times of the most frequent word appearing. **In my dataset, I used 10% cutoff, meaning I only kept the top 10% most frequent words, but when I filtered the original dataset, I still kept 97% of the content!** 

### 2.1.3 Padding the sequence

The only reason you need to pad the sequence is because if you use the batch mode, all sequences must be of the same length inside your batch. Certainly you can get away with this by setting your batch-size to 1(gradient descent on each sample) but this will significantly lower the speed of going over one epoch.

Below is the code I used to pad the sequence.

```python
MAXLENGTH = 20
PAD = 'PAD'

# Transform a list of num_samples sequences (lists of word indices) into a 2D Numpy array of shape 
padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=MAXLENGTH, dtype='int32',padding='post', truncating='post', value=PAD)
```

### 2.1.4 Special Tokens for RNN
  
There is another import note in building the vocab. Almost every Sequence to Sequence model had to use four unique placeholders: \<GO\> \<EOS\> \<UNK\> \<PAD\>.

...To put it all together, imagine we have the sentence "I go.", tokenized as ["I", "go", "."] as input and the sentence "Je vais." as output, tokenized ["Je", "vais", "."]. It will be put in the (5, 10) bucket, with encoder inputs representing [PAD PAD "." "go" "I"] and decoder inputs [GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]...

Here is a quick explanation:   

1. \<GO\> simply means it is a start of the sentence. It was often put at the begining of reponses as a signal of starting output.    
2. \<EOS\> means end of sentence. This is almost the 1st thing the model learns. Model learns to stop the output after some words. If you do not have this signal in your training data, most likely the model will try to fill up your sentences with random words.   
3. \<UNK\> this is a placeholder for those words not exist in the vocab.  
4. \<PAD\> since most sequences are in varied length, we pad the sequence to a fixed length so the model can do batch computation.  

> **Important Note! \<PAD\> should always be the 1st word in your vocab. This is required if you are going to Mask the \<PAD\> since they literally mean nothing.** 

### 2.1.5 Pretrained Embedding
  
There are two pretrained embedding, one being Word2Vec, the other one being GloVe. The difference I quoted below:

> Both models learn geometrical encodings (vectors) of words from their co-occurrence information (how frequently they appear together in large text corpora). They differ in that word2vec is a "predictive" model, whereas GloVe is a "count-based" model

Using pretrained embedding vectors (for more explanation please read below) helps the training process in two ways:

- Shorten the training time since now we have preset the first layer of the model
- It is more accurate since either Word2Vec and GloVe are trained on millions of words with massive amount of data.

All four special symbols mentioned above, except \<PAD\>, should be treated as regular words just like all other vocabs, which means they should have their unique embedding learned. **If you are using pretrained embedding, you must make sure they exit in your pretrained vocab!!!**

### 2.1.6 Python Code
```python
from keras.preprocessing.text import Tokenizer
import string

punct = string.punctuation()
punct |= ('\n', '\r', '\t')
MAX_NB_WORDS = 20000

# this function split a sentence into a list of words.
tokenizer = Tokenizer(num_words=MAX_NB_WORDS,  filters=punct, lower=True, split=" ")
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)

# returns the list of words
word_index = tokenizer.word_index
print('Found %s unique tokens.' % len(word_index))

```

### 2.1.7 Alternative Solution

Recently I read someone's work who does not train on word by word dictionary. Instead, he trained on **character by character** (like, a, b, c, ?, etc). Even if we consider the Upper case and all types of punctuations, there are at most 100 tokens. However, as you can imagine, this type of method will require massive dataset and only converges after months.    


# 3. Model Building

Building a complete model in Keras and Tensorflow is essentially the same if you understood the basic elements of a typical RNN model.  

Think of building a model as drawing a graph where the input data flows to the end. Keras made things easier in terms of simplifying the process of declaring Input and Output matrix type, gradient descent and back propagating. In Tensorflow, all these need to be set up manually.  


## 3.1 Embedding layer

Simple put, the Embedding layer is a simple matrix multiplication that transforms words into their corresponding word embeddings, or in other words, this is where model learns the meaning of each word. Even though our input is a list of integers, but both Keras and Tensorflow will transform it into a one-hot matrix in order to quickly do this as a matrix multiplication, a one-hot matrix.

### 3.1.1 Using Pretrained Model

A useful tool for pretrained Model is [Spacy](https://spacy.io/), where you can easily track the index and vector of a given word.

Below is the code:

```python
import spacy

nlp = spacy.load('en')
# vocab contains top 1 million words in pretrained GloVe
vocab = nlp.vocab
def get_embeddings(vocab, nr_unk=100):
    ''' the function to retreive the embedding space from Spacy GloVe
    Vocab is the vocab built from your text'''
    nr_vector = len(vocab) + 1 # 1 is saved for padding!!
    # preset the embedding matrix, 300 is the embedding vector length
    vectors = numpy.zeros((nr_vector, 300), dtype='float32')
    for i, lex in enumerate(vocab):
        if lex in nlp.vocab:
            # the 1st word is saved for padding!!!!
            vectors[i+1] = nlp.vocab[lex].vector / nlp.vocab[lex].vector_norm
    return vectors
```

If you do not want to use GloVe or Word2Vec, to gain a better result and save some training time, it is helpful to train the embeddings with an autoencoder and then use them as initialization of the Embedding layer for the RNN model. 

### 3.1.2 Loading Pretrained Embedding matrix

It is prettry straightforward in both Keras and TensorFlow. It is a special embedding layer that takes a pretrained matrix and outputs a hidden layer with specified size.

```python

EMBEDDING_DIM = 1024
MAX_SEQUENCE_LENGTH = 20
KEEP_PROB = 0.2

# this is a typical Keras Embedding Layer
# for masking, please refer to below section
embedding_layer = Embedding(num_words,
                            EMBEDDING_DIM,
                            weights=[pretrained_embedding], # remove this if you want to train your weight
                            input_length=MAX_SEQUENCE_LENGTH,
                            trainable=False,
                            masking=True)

#----------------------------------------------------
# this is what a typical Tensorflow Embedding Layer looks like
with tf.device("/cpu:0"): # embedding calcualtion can be done on CPU. 
    # Create new variable named 'embedding' to connect the character input to the base layer of the RNN. 
    #The function tf.get_variable() is used to get or create a variable instead of a direct call to tf.Variable

    embedding = tf.get_variable("embedding", [num_words, EMBEDDING_DIM])
    # Create an embedding tensor with tf.nn.embedding_lookup(embedding, self.input_data).
    # This tensor has dimensions batch_size x seq_length x rnn_size.
    inputs = tf.nn.embedding_lookup(embedding, input_data)

    if KEEP_PROB < 1:
        inputs = tf.nn.dropout(inputs, KEEP_PROB)
```

## 3.2 Basic LSTM/GRU Layer

Simply put, LSTM or GRU(a little variation to LSTM) is a layer that has two  inputs/outputs. One of them is called 'state', representing what was happeneing in last Timestamp and the other one is called 'Gate', deciding what should be kept and forgot at current layer (*this is very naive explanation and is very flawed, [click me for more details](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)*). We keep feeding both the state and info we learned so far to the cell itself to generate new state and new info. 

Practically I found GRU is faster to train and converge (GRU has one less gate than LSTM) and they show no apparant difference in terms of outcome accuracy.


### 3.2.1 Inplementation in Keras

In Keras, if you want to stack LSTM for few times, you need to add a special argument in first few layers except the last one: **return_sequences=True**. What it does is to return the state and info cell in sequences. It is set to False in default and if it is False, the LSTM cell only return the state of the last Timestamp.

```python

DROP_OUT_RATE = 0.2

from keras.models import Sequential
from keras.layers import LSTM, GRU

# this is a LTSM layer in Keras, you can replace LSTM with GRU
model = Sequential()

# Remember KERAS requires the 1st layer to declare the input shape
model.add(Embedding(num_words, EMBEDDING_DIM, input_shape=(?,?)))

# if you want more layers, just repeat below for few times
# dropout is optional, you can also use regularizor terms
model.add(LSTM(hidden_nr, dropout=DROP_OUT_RATE, recurrent_dropout=DROP_OUT_RATE, return_sequences=True))

model.add(LSTM(hidden_nr, dropout=DROP_OUT_RATE, recurrent_dropout=DROP_OUT_RATE))

```

### 3.2.2 Inplementation in Tensorflow

This is a LTSM layer in Tensorflow. Replacing Basic LSTMCell with GRU or LSTM cell works the same way.

```python
#----------------------------------------------------

import inspect
import tensorflow as tf
from tensorflow.contrib.rnn import BasicLSTMCell, LTSMCell, GRUCell

NUM_STEPS = 5
HIDDEN_SIZE = 1024

def lstm_cell():
      # With the latest TensorFlow source code (as of Mar 27, 2017),
      # the BasicLSTMCell will need a reuse parameter which is unfortunately 
      # not defined in TensorFlow 1.0. To maintain backwards compatibility, we 
      # add an argument check here:
    if 'reuse' in inspect.getargspec(
        tf.contrib.rnn.BasicLSTMCell.__init__).args:
        return tf.contrib.rnn.BasicLSTMCell(
            HIDDEN_SIZE, forget_bias=0.0, state_is_tuple=True,
            reuse=tf.get_variable_scope().reuse)
    else:
        # There are other choices such 
        return tf.contrib.rnn.BasicLSTMCell(
            HIDDEN_SIZE, forget_bias=0.0, state_is_tuple=True)

# drop out is a techinque of regularization,
# you can use either previous one or this one
def attn_cell():
    return tf.contrib.rnn.DropoutWrapper(
            lstm_cell(), output_keep_prob=keep_prob)

# MultiRNNCell is a TF built-in wrapper for you 
# to quickly build stacked RNN cells
cell = tf.contrib.rnn.MultiRNNCell(
        [attn_cell() for _ in range(num_layers)],
         state_is_tuple=True)

# for TF, you have to declare all the input by yourself
# remember we have two inputs, one is the state, one is the info
_initial_state = cell.zero_state(batch_size, tf.float32)
outputs = []
state = self._initial_state

# use varibale_scope to name this graph node
with tf.variable_scope("RNN"):
    for time_step in range(NUM_STEPS):
        if time_step > 0: 
            tf.get_variable_scope().reuse_variables()
        (cell_output, state) = cell(inputs[:, time_step, :], state)
        outputs.append(cell_output)

```

## 3.3 Decoder and Loss

### 3.3.1 Basic Explanation

Below is a graph of the basic decoder.  

![RNN Model](/assets/images/RNNmodel.png)  

As you can see, decoder is another set of RNN layers stacked over each other. **The idea of RNN decoder(regardless of TF or Keras)is to use your previous output as next input. The final output will then become a list of outputs at different time stamp. This is implemented slightly different in Keras and Tensorflow and this is why we are able to concatenate the output from different timestamp and do batch calculation all in once.**.

There are many other techniques, such as Peeking-Decoder, Decoder with attention, etc. However, as I have mentioned above, not all of them were not implemented in Keras at this moment. 

### 3.3.2 Keras 

I have write down the complete code here. This is just a toy example of sequence to sequence model in Keras.

```python

from keras.layers import Layer, Dense, RepeatVector
from keras.layers import Activation, Dropout, Embedding, TimeDistributed
from keras.optimizers import Adam

MAX_LENGTH =20
EMBED_SIZE = 1024
HIDDEN_SIZE = 1024
# This is an example of Keras encoder and decoder.
model.add(Embedding(vocab_size,
                        EMBED_SIZE, #
                        input_length=MAX_LENGTH,
                        name='embed',
                        mask_zero=True)) 
model.add(LSTM(HIDDEN_SIZE, return_sequences=True))                        
model.add(LSTM(HIDDEN_SIZE))
# LSTM returns the embedding info at the last Timestamp
# we repeat the info for n times, n is the sequence length
# of target output. To generate the output in sequence,
# output at each timestamp was fed into LSTM cell as input. 
# That's why I used few LSTM cells returning sequences stacked
# over each other.
model.add(RepeatVector(MAX_LENGTH))
model.add(LSTM(HIDDEN_SIZE, return_sequences=True))
model.add(LSTM(HIDDEN_SIZE, return_sequences=True))
# Use TimeDistributed Layer to catch the output at each
# timestamp, namely the words in sequence in our case.
model.add(TimeDistributed(Dense(vocab_size)))
model.add(Activation('softmax'))

# this is the clipping norm, read below section for details
adam = Adam(clipnorm=1.) 
# ...Compile it...
model.compile(
        optimizer=adam, # we use Adam Optimizer
        # and categorical entrophy for loss
        loss='categorical_crossentrophy', 
        )

# Till now, a complete model in Keras is set up.

```

### 3.3.3 Tensorflow

We have defined our outputs in previous section. As I explained previously, output of the RNN cell in different timestamp is essentially now the target word in sequence. Therefore, we concat the everything and activate once in batch.

Note the following comment in rnn_cell.py:

> Note: in many cases it may be more efficient to not use this wrapper, but instead concatenate the whole sequence of your outputs in time, do the projection on this batch-concatenated sequence, then split it if needed or directly feed into a softmax.

Below codes follows previous Tensorflow example. I have commented in details for easy understanding.

```python
#-----------------------Tensorflow Example----------------------------------

# Continue with previous example.

# tf.concat concatenates the output tensors along the rnn_size dimension,
# to make a single tensor of shape [batch_size x (seq_length * rnn_size)].

# Concat output:  [(rnn output: batch 0, seq 0) (rnn output: batch 0, seq 1) ... (rnn output: batch 0, seq seq_len-1)]

# Reshape Output:       
#   [rnn output: batch 0, seq 0]
#   [rnn output: batch 0, seq 1]
#   ...
#   [rnn output: batch 0, seq seq_len-1]

output = tf.reshape(tf.concat(axis=1, values=outputs), [-1, HIDDEN_SIZE])

# Create new variable softmax_w and softmax_b for output.
# softmax_w is a weights matrix from the top layer of the model (size of hidden nuerons)
# to the vocabulary output (of size vocab_size).
softmax_w = tf.get_variable(
        "softmax_w", [HIDDEN_SIZE, vocab_size], dtype=tf.float32)
# softmax_b is a bias vector of the ouput characters (of size vocab_size).
softmax_b = tf.get_variable("softmax_b", [vocab_size], dtype=tf.float32)
# Obtain logits node by applying output weights and biases to the output tensor.
# Logits is a tensor of shape [(batch_size * seq_length) x vocab_size].
# Recall that outputs is a 2D tensor of shape [(batch_size * seq_length) x rnn_size],
# and softmax_w is a 2D tensor of shape [rnn_size x vocab_size].
# The matrix product is therefore a new 2D tensor of [(batch_size * seq_length) x vocab_size].
# In other words, that multiplication converts a loooong list of rnn_size vectors
# to a loooong list of vocab_size vectors.
# Then add softmax_b (a single vocab-sized vector) to every row of that list.
# That gives you the logits!
logits = tf.matmul(output, softmax_w) + softmax_b

```

## 3.4 Loss, Gradient Descent, and Optimizer

Every single model has the same process:
- Predict
- Calculate loss
- Optimize the learning rate
- Back Propagate
- Repeat above till converge

### 3.4.1 Loss Function

Categorical Cross Entrophy is the most common almost default loss function used in such tasks.

>Categorical Cross Entrophy: L = -sum(y * log(y_prediction)) where y is the probability distribution of true labels (typically a one-hot vector) and y_prediction is the probability distribution of the predicted labels, often coming from a softmax.  

In Tensorflow, most RNN tasks use built-in Sequence_loss Function to calculate the loss (**it is essentially Weighted cross-entropy loss for a sequence of logits**). 

### 3.4.2 Gradient Descent

It is important to choose the batch size for gradient descent. 

*Basically, the smaller batch size you choose, the longer time one epoch is going to take and the more likely your model is going to overfit*. I used batch-size of 20 for my chatbot. 

>If you are dealing with sequences in different length, instead of padding them into fixed length (which is required for batch calculation), you can choose to set batch size to 1 so the model does gradient descent per each sample point.

### 3.4.3 Optimizer

Optimizer helps to control the learning rate over training epoch. It will be reset at the begining of every epoch.

Most of translation tasks or conversational bot in our case, used Adam Optimizer these days. One of the concerns regarding Adam Optimizer is that it tends to overfit. Personally I have not even got close to overfit in such task but it maybe true for tasks like RNN classfication, etc. RMSprop is also said to be another good choice. I have tried both and they do not show much difference to me. 

### 3.4.4 Gradient Clipping

**Gradient Clipping** is a technique to prevent exploding gradients in very deep networks, typically RNN. There exist various ways to perform gradient clipping, but the a common one is to normalize the gradients of a parameter vector when its L2 norm exceeds a certain threshold according to new_gradients = gradients * threshold / l2_norm(gradients). [more info](http://jmlr.csail.mit.edu/proceedings/papers/v28/pascanu13.pdf)  

Clipping was passed in as an argument to the Optimizer in Keras([documentation](https://keras.io/optimizers/)). We will be more clear on this process in below Tensorflow Example.

### 3.4.5 Keras

There is no more code need to be done for Keras at this point.

### 3.4.6 Tensorflow

#### 3.4.6.1 Loss

```python

LEARNING_RATE = 6e-5
BATCH_SIZE =20
SEQ_LENGTH = 20

loss = seq2seq.sequence_loss_by_example([logits], # logits: 1-item list of 2D Tensors of shape [batch_size x vocab_size]
        [tf.reshape(targets, [-1])], # targets: 1-item list of 1D batch-sized int32 Tensors of the same length as logits
        [tf.ones([batch_size * seq_length])], # weights: 1-item list of 1D batch-sized float-Tensors of the same length as logits
        vocab_size) # num_decoder_symbols: integer, number of decoder symbols (output classes)
```

#### 3.4.6.2 Optimizer

In Tensorflow, optimizer is a seperate tensor where user need to run manually. Gradient Clipping also needs to be applied by hand. However, the idea is the same and we get to know the typical workflow of a neural network.


```python
#-------Simplified Version-------------
# You can just ask TF to minimize the loss for you

# train_op = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(self.loss)  

#--------Complete Version--------------      
# Cost is the arithmetic mean of the values of the loss tensor
# (the sum divided by the total number of elements).
# It is a single-element floating point tensor. This is what the optimizer seeks to minimize.
cost = tf.reduce_sum(loss) / BATCH_SIZE / SEQ_LENGTH
# Create a summary for our cost.
tf.summary.scalar("cost", cost)
# Create a node to track the learning rate as it decays through the epochs.
lr = tf.Variable(LEARNING_RATE, trainable=False)
global_epoch_fraction = tf.Variable(0.0, trainable=False)
global_seconds_elapsed = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables() # tvars is a python list of all trainable TF Variable objects.

# tf.gradients returns a list of tensors of length len(tvars) where each tensor is sum(dy/dx).
grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),grad_clip)
# Use ADAM optimizer with the current learning rate.
optimizer = tf.train.AdamOptimizer(lr) 
# Zip creates a list of tuples, where each tuple is (variable tensor, gradient tensor).
# Training op nudges the variables along the gradient, with the given learning rate, using the ADAM optimizer.
# This is the op that a training session should be instructed to perform.
self.train_op = optimizer.apply_gradients(zip(grads, tvars))
self.summary_op = tf.merge_all_summaries()
```

## 3.5 Attention/Bidirectional LSTM

[Here](http://distill.pub/2016/augmented-rnns/) is a very good explanation on so called Augmented RNNs. 
Generally, Attention Model is an extra layer that helps the model to carry long-term memory of focus on certain part of the sentence. Below are examples of how they are implemented in Keras and Tensorflow.

```python

#Keras TO-DO

#--------TensorFlow Example---------------

from tf.contrib.rnn import AttentionCellWrapper

# TO-DO
```

Bidirectional LSTM came from a [study](https://www.cs.toronto.edu/~graves/asru_2013.pdf) that shows input information from the past and future of the current time frame can be used unlike standard RNN which requires the delays for including future information.

```python

# TO-DO
```

## 3.6 Plot the Model Structure

In **Keras**, there are some useful tools for you to draw out the model structure. Below is an example of the toy model I built:

![KerasModel](/assets/images/KerasModel.png)

Here is the code to draw a model:

```python
from IPython.display import SVG
# you need to install some depending modules for this to work
from keras.utils.visualize_util import model_to_dot, plot

# assume build_model is the function you wrote to build the Keras model
model = build_model()
SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))
```

# 4. Training

Till now, we have built models in both Keras and Tensorflow. Training in Keras is merely calling train function. However, in Tensorflow, it is much more complicated.

## 4.1 Keras

```python 

# checkpoint to save the best model
filepath="weights.best.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]
    
'''depending on data size, you may not be able to 
load the whole dataset for training, it is helpful to
write a generator for your model'''
X_train, X_test, Y_train, Y_test = get_training_batch(datasource):

# I set epoch to 1 because we are using our own generator, for more explanation
# you can search for keras documentation
model.fit(X_train, Y_train, validation_split=0.05, batch_size=20, epochs=1,callbacks=callbacks_list, verbose=2)

save_model(model)

```

## 4.2 WorkFlow in Tensorflow

The basic workflow in Tensorflow:
- Create a session where you write down the graph and run the model
- Specify the Inputs and Outputs, both of which live on the Session we created. Output is a list of items we would need, including:
  -Training Loss
  -Inner State of the model
  -Current Learning Rate optimized by the optimizer
  -Summary of the model
- We manually log the epoch and every batch so we can resume if we stopped the trainning process
- For every Epoch, reset the Initiate State (but not restting the weights, etc)
- For every batch, assign the new Learning Rate(optimized by the optimizer) and carry over the initiate state from last Batch, run the session which will calcuate the loss and do Gradient Descent again. 

```python


#-----------------TensorFlow Example------------------------

SAVE_EVERY = 100 # save the model every 100 batches
TOTAL_BATCH_COUNT = ? # you should calculate this based on your data size
DECAY_STEPS = 100000
DECAY_RATE = 0.95

 # Create the model! Assume you have Model Class
 # that built up the model
model = Model(args)

config = tf.ConfigProto(log_device_placement=False)
# this is to allow your machine to use more GPU
# space as needed
config.gpu_options.allow_growth = True

with tf.Session(config=config) as sess:
    # first, you need to initiate all the variables
    # Same thing is required if you loaded a pretrained model
    tf.initialize_all_variables().run()
    # create a saver object
    saver = tf.train.Saver(model.save_variables_list())
    if (load_model):
        print("Loading saved parameters")
        saver.restore(sess, ckpt.model_checkpoint_path)
    global_epoch_fraction = sess.run(model.global_epoch_fraction)
    global_seconds_elapsed = sess.run(model.global_seconds_elapsed)

    initial_batch_step = int((global_epoch_fraction
                - int(global_epoch_fraction)) * TOTAL_BATCH_COUNT)
    epoch_range = (int(global_epoch_fraction),
                num_epochs + int(global_epoch_fraction))

    # specify the output 
    outputs = [model.cost, model.final_state, model.train_op, model.summary_op]
    # if model is lstm, we need to load both hidden status and info carried
    is_lstm = (model == 'lstm')

    global_step = epoch_range[0] * TOTAL_BATCH_COUNT + initial_batch_step
    try:
        for e in xrange(*epoch_range):
            # e iterates through the training epochs.
            # Reset the model state, so it does not carry over from the end of the previous epoch.
            state = sess.run(model.initial_state)
            batch_range = (initial_batch_step, TOTAL_BATCH_COUNT)
            initial_batch_step = 0
            for b in xrange(*batch_range):
                global_step += 1
                # every 100k steps, we decay the Learning Rate
                if global_step % DECAY_STEPS == 0:
                    # Set the model.lr element of the model to track
                    # the appropriately decayed learning rate.
                    current_learning_rate = sess.run(model.lr)
                    current_learning_rate *= DECAY_RATE
                    # updating learning rate of the model
                    sess.run(tf.assign(model.lr, current_learning_rate))
                    print("Decayed learning rate to {}".format(current_learning_rate))
                    start = time.time()
                    # Pull the next batch inputs (x) and targets (y) from the data loader (you should have a generator ready for training).
                    x, y = data_loader.next_batch()

                    # feed is a dictionary of variable references and respective values for initialization.
                    # Initialize the model's input data and target data from the batch,
                    # and initialize the model state to the final state from the previous batch, so that
                    # model state is accumulated and carried over between batches.
                    feed = {model.input_data: x, model.targets: y}
                    if is_lstm:
                        # for LSTM model, there are two states we need to 
                        # carry over
                        for i, (c, h) in enumerate(model.initial_state):
                            feed[c] = state[i].c
                            feed[h] = state[i].h
                    else:
                       # if you are certain you are just using LSTM, just use previous one and discard below
                        for i, c in enumerate(model.initial_state):
                            feed[c] = state[i]
                    # Run the session! Specifically, tell TensorFlow to compute the graph to calculate
                    # the values of cost, final state, and the training op.
                    # Cost is used to monitor progress.
                    # Final state is used to carry over the state into the next batch.
                    # Training op is not used, but we want it to be calculated, since that calculation
                    # is what updates parameter states (i.e. that is where the training happens).
                    train_loss, state, _, summary = sess.run(outputs, feed)
                    elapsed = time.time() - start
                    global_seconds_elapsed += elapsed
                    print "{}/{} (epoch {}/{}), loss = {:.3f}, time/batch = {:.3f}s" \
                        .format(b, batch_range[1], e, epoch_range[1], train_loss, elapsed)
                    # Every save_every batches, save the model to disk.
                    # By default, only the five most recent checkpoint files are kept.
                    if (e * batch_range[1] + b + 1) % SAVE_EVERY == 0 \
                            or (e == epoch_range[1] - 1 and b == batch_range[1] - 1):
                        save_model(sess, saver, model, args.save_dir, global_step,
                                data_loader.total_batch_count, global_seconds_elapsed)
        except KeyboardInterrupt:
            # Introduce a line break after ^C is displayed so save message
            # is on its own line.
            print()
        finally:
            writer.flush()
            global_step = e * TOTAL_BATCH_COUNT + b
            save_model(sess, saver, model, args.save_dir, global_step,
                    TOTAL_BATCH_COUNT, global_seconds_elapsed)

```


# 5. Summary

This is the end of our journey of RNN sequence to sequence model building. In this Blog I have covered all the basic layers that are used in a very practical manner. Instead of providing a mathmatic explation on the neural network, I tried to explain the usage of these layers. By doing so, I hope you will have a better understanding of the workflow in a typical recurrent nueral network.

The blog was finished in a rush and there are definitely a lot of details I did not cover. 

If you have any questions or you'd like to point out some errors I made, feel free to leave a comment or reach out to me via email.

Thanks!


# Appendix

1. Keras giving NaN as accuracy or loss?
  You should try to add clipping function to Optimizer. If it doesn't work,  set your target variable to data type of Numpy.Float64 or higher instead of Numpy.Bool. Last solution, increase your memory size or lower your matrix dimension. 

2. Installing GloVe 

It takes really long time for me to install GloVE on Mac. The reason turns out to be Mac default c language complie is clang, but we need to set it to the recent version of gcc, which usually stores at **/usr/local/bin/gcc-6**.  
The easiest way is to:  

```command
cd /usr/local/bin
ln -s gcc-6
which gcc
gcc --version
```

3. To set up correct jupyter notebook env on AWS

```command
pip install ipykernel
python -m ipykernel install --user --name ENVNAME --display-name "Python (whatever you want to call it)"
```
